{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4279c909",
   "metadata": {},
   "source": [
    "# Transforming DataFrames\n",
    "\n",
    "### I. Sorting\n",
    "\n",
    "`df.sort_values(\"column_name\")`: sorts a df according to ascending row\n",
    "`df.sort_values(\"column_name\", ascending = False)`: largest first\n",
    "\n",
    "#### a. Sorting by multiple columns:\n",
    "\n",
    "`df.sort_values([\"column_name1\", column_name2\"], ascending = [True, False])`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf3091b",
   "metadata": {},
   "source": [
    "### II. Subsetting rows\n",
    "\n",
    "`df[\"column_name\"]`: returns the specified column \n",
    "\n",
    "> <span style = \"color:royalblue\"> to subset multiple columns pass in a list of column names.  </span>\n",
    "\n",
    "#### a. Using Comparison Operators\n",
    "\n",
    "`df[\"column_name\"] > 50`: returns boolean values relative to comparison operator **for the specified column**\n",
    "\n",
    "> <span style = \"color:royalblue\"> \n",
    "the comparison conditions can be used within square brackets to subset the rows we are interested in.</span>\n",
    "\n",
    "> `df[df[\"column_name\"] > 50]`: returns all rows relative to > condition. Other comparison operators can be used as well.\n",
    "\n",
    "#### b. Subsetting based on multiple conditions\n",
    "\n",
    "Use the following three steps together:\n",
    "1. `variable1 = df[\"column1\"] == \"some_filter_value\"`\n",
    "2. `variable2 = df[\"column2\"] == \"some_filter_value\"`\n",
    "3. `df[variable1 & variable2]`\n",
    "\n",
    "> this will subset based upon the conditions specified in variable 1 & variable 2. \n",
    "\n",
    "#### c.Â Subsetting using .isin()\n",
    "\n",
    "`some_filter_var = df[\"column\"].isin([\"filter_value1\", \"filter_value2\"])` <br>\n",
    "`df[some_filter_var]`: returns the rows subset by filter_value1 and 2 from the column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fd157f",
   "metadata": {},
   "source": [
    "### IV. Creating a new Column\n",
    "\n",
    "`df[\"new_column_name\"] = df[\"old_column_name\"] / 100`\n",
    "> <span style = \"color:royalblue\"> here `/ 100` is an example of manipulating data to get different values to be stored in the new column </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d813f14",
   "metadata": {},
   "source": [
    "### V. Groupby and Aggregating\n",
    "\n",
    "`.agg({'column1': \"oper\"})` for one operation <br>\n",
    "`.agg({'column1': [\"oper1\", \"oper2\"]})`: for multiple operations\n",
    "\n",
    "> <span style = \"color:royalblue\"> note that the summations are passed in as values of a dict; while columns are the key of the passed in dict. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d25f294",
   "metadata": {},
   "source": [
    "### Explicit indexes\n",
    "\n",
    "**`df.columns`** contains an index object of column names\n",
    "\n",
    "**`df.index`** contains an index object of row numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c4bfc5",
   "metadata": {},
   "source": [
    "### Setting a column as the index\n",
    "\n",
    "**`df_ind = df.set_index(\"name\")`** moves a column from the body of the df to the index. \n",
    "<br>\n",
    "<span style = \"color:indianred\"> Note that **df_ind** (here and below) is a user defined variable to represent the df with a named index</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0e413e",
   "metadata": {},
   "source": [
    "#### pre-index assignment:\n",
    "\n",
    "![pre-index](pre-index.png)\n",
    "\n",
    "#### post-index assignment:\n",
    "\n",
    "![post-index](post-index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7862a74",
   "metadata": {},
   "source": [
    "### Removing an index\n",
    "\n",
    "**`df_ind.reset_index()`**: resets to original df <br>\n",
    "**`df_ind.reset_index(drop = True)`**: removes the named index altogether"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f434e3c",
   "metadata": {},
   "source": [
    "### Subsetting using an index\n",
    "\n",
    "**`df_ind.loc[[\"name\", \"name\"]]`** filters on **index values**. <br>\n",
    "> <span style = \"color:royalblue\"> index values **do not** need to be unique. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1595e7e8",
   "metadata": {},
   "source": [
    "### Multi-level indexes\n",
    "\n",
    "**`df_ind = df.set_index([\"name\", \"name\"])`** creates a heirarchical index\n",
    "\n",
    "> <span style = \"color:royalblue\"> when using **.loc** on a multi-index, all inner indexes that match the called outer index will be returned. Passing a list of named indexes will return a list of information matching the **outer indexes**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a804fb9",
   "metadata": {},
   "source": [
    "![multi-index](multi-index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8245ca",
   "metadata": {},
   "source": [
    "### Subsetting on inner levels with a list of tuples\n",
    "\n",
    "`df_ind = df.set_index([(\"outer name1\", \"inner name1\"), (\"outer name2\", \"inner name2)])`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d8d49f",
   "metadata": {},
   "source": [
    "### Sorting by index values\n",
    "\n",
    "`df_ind.sort_index()`: sorts all indexes from outer to inner in ascending order\n",
    "\n",
    "#### to control the sorting: \n",
    "\n",
    "`df_ind.sort_index(level= [\"index name1\", \"index name2\"], ascending= [True, False])`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712c24ea",
   "metadata": {},
   "source": [
    "### Slicing by index values (sort first)\n",
    "\n",
    "#### By outer only:\n",
    "**`df.loc[\"outer name1\": \"outer name2\"]`**\n",
    "\n",
    "#### By inner also:\n",
    "**`df.loc[(\"outer name1\", \"inner name1\") : (\"outer name2\", \"inner name2)]`**\n",
    "\n",
    "> <span style = \"color:indianred\"> Note that pd will not throw an error if you try to slice only by inner indexes</span>\n",
    "\n",
    "### Slicing by column \n",
    "\n",
    "#### Subsetting columns, while keeping all rows:\n",
    "**`df.loc[:, \"column1\":\"column2\"]`**\n",
    "\n",
    "#### Slicing on columns and rows:\n",
    "**`df.loc[(\"outer name1\", \"inner name1\") : (\"outer name2\", \"inner name2), \"column1\":\"column2\"]`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12da222",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br> \n",
    "\n",
    "# Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410411d6",
   "metadata": {},
   "source": [
    "`df.isna()`: returns a boolean value if the value is missing or not\n",
    "<br>\n",
    "\n",
    "`df.isna().any()`: returns a boolean value at the column level for any missing values in a particular column\n",
    "<br>\n",
    "\n",
    "`df.isna().sum()`: counts the number of missing values in a given column\n",
    "\n",
    "> <span style = \"color:royalblue\"> you can plot the sum of missing values for a clear review of missing content  </span>\n",
    "<br>\n",
    "\n",
    "`df.dropna()`: removes the rows with the missing data from the dataframe\n",
    "<br>\n",
    "\n",
    "`df.fillna(0)`: fills the missing values with 0, so as to not lose the other information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2953dd4f",
   "metadata": {},
   "source": [
    "# Creating DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee7c9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\n",
    "    \"key1\": 1,\n",
    "    \"key2\": 2,\n",
    "    \"key3\": 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da42aa2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict[\"key1\"] # acces value via keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce66d1ee",
   "metadata": {},
   "source": [
    "#### A. From a list of dictionaries\n",
    "\n",
    "- constructed row by row\n",
    "\n",
    "#### B. From a dictionary of lists\n",
    "\n",
    "- constructed column by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c28186",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts = [\n",
    "    {\"key1\": 1,\"key2\": 2,\"key3\": 3},\n",
    "    {\"key1\": 4, \"key2\": 5, \"key3\": 6}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6681550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th>key3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key1  key2  key3\n",
       "0     1     2     3\n",
       "1     4     5     6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(list_of_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a8c74b",
   "metadata": {},
   "source": [
    "#### Dict of lists\n",
    "\n",
    "- **key** = column name\n",
    "- **value** = list of column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1595a000",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_lists = {\n",
    "    \"key1\": [1,2],\n",
    "    \"key2\": [3,4],\n",
    "    \"key3\": [5,6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2564f4cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th>key3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key1  key2  key3\n",
       "0     1     3     5\n",
       "1     2     4     6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dict_of_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a35a5c",
   "metadata": {},
   "source": [
    "# Data Merging Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f904586",
   "metadata": {},
   "source": [
    "#### Inner Join\n",
    "\n",
    "`\"some_variable\" = df1.merge(df2, on= \"column\")`\" will merge df1 with df2 on the specified column present in both dfs \n",
    "\n",
    "#### Suffixes\n",
    "\n",
    "`\"some_variable\" = df1.merge(df2, on= \"column\", suffixes=(\"_df1_short\", \"_df2_short\"))`: adds a suffix to columns so that we know which df the column came from"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeefa34",
   "metadata": {},
   "source": [
    "### Kinds of Relationships between tables\n",
    "\n",
    "#### One-to-one\n",
    "\n",
    "> every row in the left table is related to **one and only one** row in the right table\n",
    "\n",
    "#### One-to-many\n",
    "\n",
    "> every row in the left table is related to **one or more** rows in the right table. As a result, values from the left table will be repeated to match those in the right table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26dfaeb",
   "metadata": {},
   "source": [
    "### Merging multiple DataFrames\n",
    "\n",
    "#### Single merge with multiple columns\n",
    "\n",
    "`df1.merge(df2, on = ['col1', 'col2'])`\n",
    "\n",
    "#### Multiple DataFrames\n",
    "\n",
    "`df1.merge(df2, on = ['col1', 'col2']) \\\n",
    ".merge(df3, on='col3', suffixes=('_col1&2_short1', '_col3_short'))`\n",
    "- a \\ was used after cols1&2 to make a new line, which is read as one line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48409aae",
   "metadata": {},
   "source": [
    "#### Even more tables\n",
    "\n",
    "`df1.merge(df2, on=\"col\")\\\n",
    "   .merge(df3, on=\"col\")\\\n",
    "   .merge(df4, on=\"col\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2ff9f0",
   "metadata": {},
   "source": [
    "### Left Join\n",
    "\n",
    "- Returns all rows of data from the left table, and only those from the right table where key columns match.\n",
    "- One of the key values is to make sure that you don't lose information from the original table (as you would with an inner join)\n",
    "\n",
    "![left-join](left-join.png)\n",
    "<br>\n",
    "<br>\n",
    "`df1.merge(df2, on = 'id', how = 'left')`\n",
    "> <span style = \"color:royalblue\"> note the addition of **how = 'left'** to signify the use of a left join </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedc83e8",
   "metadata": {},
   "source": [
    "### Right Join\n",
    "\n",
    "- (Mirror opposite of left join.) Returns all rows of data from the right table, and only those from the left table where key columns match.\n",
    "\n",
    "`df1.merge(df2, how = 'right',\n",
    "            left_on= 'id', right_on = 'id2')`\n",
    "\n",
    "> <span style = \"color:royalblue\"> note the addition of **left on** and **right on**. They allow us to tell the merge which key columns from each table to merge the tables. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a063f7d",
   "metadata": {},
   "source": [
    "### Outer Join\n",
    "\n",
    "- Returns all fo the rows from both tables regardless if there is a match.\n",
    "\n",
    "`df1.merge(df2, on= \"id\", how = 'outer', suffixes=('_out1', '_out2'))`\n",
    "\n",
    "> <span style = \"color:royalblue\"> note suffixes are especially relevant because there will be numerous unmatched values returned. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd83568e",
   "metadata": {},
   "source": [
    "### Self Join (Merging a table to itself)\n",
    "\n",
    "Merging a table to itself can allow you to compare values in a column to other values in the same column.\n",
    "\n",
    "`df1.merge(df1, left_on= \"some_id\", right_on = \"some_other_id\", \n",
    "    suffixes= ('_id1', '_id2'))`\n",
    "    \n",
    "> <span style = \"color:royalblue\"> note that you can use left, right, and outer joins when joining a table to itself </span>\n",
    "\n",
    "#### when you might use this method:\n",
    "- heirachical relationships\n",
    "- sequential relationships\n",
    "- graph data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7d7ff0",
   "metadata": {},
   "source": [
    "### Merging on indexes\n",
    "\n",
    "The merge method automatically adjusts to accept index names or column names. The only difference is that your 'on' statment must mention the index title.\n",
    "\n",
    "> <span style = \"color:royalblue\">if the data starts as a csv file, we can use the index_col argument to set the explicit index</span> \n",
    "<br>\n",
    "> `some_variable = pd.read_csv('text.csv', index_col=['id'])`\n",
    "\n",
    "\n",
    "#### Merging a multiindex dataset\n",
    "\n",
    "![multi-index-join](multi-index-join.png)\n",
    "\n",
    "##### would take the following code:\n",
    "\n",
    "`samuel_casts = samuel.merge(casts, on=['movie_id', 'cast_id'])`\n",
    "\n",
    "\n",
    "#### When two indexes have different names:\n",
    "\n",
    "`some_variable = df1.merge(df2, left_on='id', left_index = True, \n",
    "                right_on = 'some_id', right_index = True)`\n",
    "\n",
    "> <span style = \"color:royalblue\">note you **would** use right_on & left_on if the indexes have different names, but matching values. Note also the addition of **left and right_index** </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03562d7",
   "metadata": {},
   "source": [
    "# Filtering Joins\n",
    "\n",
    "#### Mutating joins:\n",
    "\n",
    "- Combines data from two tables based on matching observations in both tables\n",
    "\n",
    "#### Filtering joins:\n",
    "\n",
    "- Filter observations from table based on whether or not they match an observation in another table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a1a32",
   "metadata": {},
   "source": [
    "### Semi Join (or filterin join)\n",
    "\n",
    "- Filters the left table down to the observations that have a match in the right table.\n",
    "- Similar to an inner join; shows an intersection\n",
    "- However, it returns only columns from the left table and ***not*** the right.\n",
    "- No duplicate rows from the left table are returned, even if there is a one-to-many relationship.\n",
    "#### step 1.  (merge tables with an inner join)\n",
    "\n",
    "`\"some_variable\" = df1.merge(df2, on= 'id')`\n",
    "\n",
    "\n",
    "#### step 2. (use .isin() method to see if 'id' is found in the newly created table)\n",
    "- this creates a series of boolean values by which we filter. \n",
    "\n",
    "`df1['id'].isin(\"some_variable\"['id'])`\n",
    "\n",
    "#### step 3. (use that line of code to subset the newly created table)\n",
    "\n",
    "`\"target_new_variable\" = df1[df1['id'].isin(\"some_variable\"['id'])]`\n",
    "\n",
    "> <span style = \"color:royalblue\">note only steps 1 and 2 are written. Step two isolates the filtering process to make the idea sequential and clear. </span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f895391e",
   "metadata": {},
   "source": [
    "### Anti join\n",
    "\n",
    "- Returns observations in the left table that do not havea. matching observation in the right table.\n",
    "- Only returns columns from the left table\n",
    "\n",
    "#### step 1. (merge tables with a left join)\n",
    "`\"some_variable\" = df1.merge(df2, on ='id', how='left', indicator=True)`\n",
    "\n",
    "> <span style = \"color:royalblue\">note the indicator argument is used. A column \"_merge\" is created which tells the source of each row. </span> \n",
    "\n",
    "#### step 2. (use .loc to identify \"left only\")\n",
    "`\"some_diff_variable\" = \"some_variable\".loc[\"some_variable\"['_merge'] == 'left_only', 'id]`\n",
    "\n",
    "> <span style = \"color:royalblue\">the above creates a list of 'ids' not in the right table </span>\n",
    "\n",
    "#### step 3. (use the .isin() method to filter for the rows with 'id' in \"some_diff variable\")\n",
    "`\"target_new_variable\" = df1[df1['id'].isin(\"some_diff_variable\")]`\n",
    "\n",
    "> <span style = \"color:indianred\"> note that all three steps are written out, unlike semi join above</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dda24c",
   "metadata": {},
   "source": [
    "## Concatenate two tables vertically\n",
    "\n",
    "`pd.concat(axis=0)`: adds table together vertically *axis=0, is vertical*\n",
    "\n",
    "### Basic concatenation\n",
    "\n",
    "`pd.concat([df1, df2, df3])`: axis 0 is default so we don't need to set\n",
    "\n",
    "> `ignore_index=True`: where the index is of no value\n",
    "\n",
    "### Setting labels to original tables (creates a multi index table)\n",
    "\n",
    "`pd.concat([df1, df2, df3],\n",
    "        ignore_index = False,\n",
    "        keys=['id1', 'id2', 'id3'])`\n",
    "        \n",
    "> <span style = \"color:indianred\"> ensure **ignore_index** is set to false because you can't add a key and ignore indexes. </span>\n",
    "\n",
    "\n",
    "### Concat with different column names\n",
    "\n",
    "#### leaving column names:\n",
    "`pd.concat([df1, df2], sort = True)`: sorts the columns by name <br> \n",
    "`pd.concat([df1, df2], join = 'inner')`: returns only the matching columns\n",
    "\n",
    "> <span style = \"color:indianred\"> sort has no effect when using an inner join </span>\n",
    "\n",
    "### Using append method\n",
    "\n",
    "**`.append()`**\n",
    "- simplified version of `.concat()`\n",
    "- supports `ignore_index` and `sort`\n",
    "- does **not** support: `keys` and `join`: *always* `join = outer`\n",
    "\n",
    "\n",
    "`pd.append([df1, df2],\n",
    "        ignore_index = True,\n",
    "        sort = True])`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732455dc",
   "metadata": {},
   "source": [
    "## Verifying identity\n",
    "\n",
    "<span style = \"color:indianred\"> This process saves us from potentially having a mean skewed by duplication values, or from creating innacurate plots. </span>\n",
    "\n",
    "#### validating merges\n",
    "\n",
    "`.merge(validate = None)`: checks if the merge is of a specified type\n",
    "- `one_to_one`\n",
    "- `one_to_many`\n",
    "- `many_to_one`\n",
    "- `many_to_many`\n",
    "\n",
    "#### verifying concatenations\n",
    "`.concat(verify_integrity=False)`: checks whether the new concatenated index contains duplicates\n",
    "- default value is false\n",
    "- only checks index; not columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ab784",
   "metadata": {},
   "source": [
    "# Merge_ordered()\n",
    "\n",
    "`pd.merge_ordered(df1, df2)`: the results are similar to merge with outer join, but the result is sorted. \n",
    "\n",
    "#### merge_ordered is similar to merge\n",
    "\n",
    "- contains on, left_on, right_on\n",
    "- type of join `how`\n",
    "- overlapping column names\n",
    "- starts as outer join (not inner, like `merge`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211ba408",
   "metadata": {},
   "source": [
    "### Forward fill\n",
    "\n",
    "`pd.merge_ordered(df1, df2, on = 'id', \n",
    "                suffixes = ('_df1short', '_df2short'),\n",
    "                fill_method = 'ffill')`\n",
    "                \n",
    "> fills the missing values of a row, with the values in the row beofre it.\n",
    "\n",
    "**when to use:**\n",
    "- ordered data/time series\n",
    "- filling in missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360409c",
   "metadata": {},
   "source": [
    "# Merge_asof()\n",
    "\n",
    "Matches on the nearest value columns rather than equal values.\n",
    "\n",
    "`pd.merge_asof(df1, df2, on = 'id', \n",
    "                suffixes=('_df1short', '_df2short'))`\n",
    "\n",
    "> <span style = \"color:indianred\"> it is **imperative** that rows are sorted prior to using merge_asof() </span>\n",
    "\n",
    "- returns values from the left table; however\n",
    "\n",
    "- the row selected from the right table is the last row whose 'column' value is **less than or equal to** the 'column' value in the left table. \n",
    "\n",
    "![merge-asof](merge-asof.png)\n",
    "\n",
    "### Merge_asof() with direction\n",
    "\n",
    "`pd.merge_asof(df1, df2, on = 'id', \n",
    "                suffixes=('_df1short', '_df2short'),\n",
    "                direction='forward')`\n",
    "                \n",
    "> <span style= color:royalblue> `direction=\"forward\"` changes the behavior of the method to select the first row in the right table whose \"on\" key column is **greater than or equal to** the left's key column. </span>\n",
    "\n",
    "#### when to use merge_asof()\n",
    "\n",
    "- Data sampled from a process\n",
    "- Developing a training set (no data leakage)\n",
    "- Time series training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019da16e",
   "metadata": {},
   "source": [
    "## Comparison of .merge_ordered() and .merge_asof()\n",
    "\n",
    "![order-asof](ordered-asof-review.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302e3387",
   "metadata": {},
   "source": [
    "# .query() method\n",
    "\n",
    "`df.query('SOME SELECTION STATEMENT')`\n",
    "\n",
    "Accepts an input string:\n",
    "- input string used to determine what rows are returned\n",
    "- input string similar to statement after WHERE caluse in SQL statement\n",
    "<br>\n",
    "\n",
    "Example selection statemtent:\n",
    "\n",
    "> `stocks.query('nike >= 90')`\n",
    "\n",
    "\n",
    "> <span style = \"color:royalblue\"> note that `and` and `or` can be used in selection statements </span>\n",
    "\n",
    "#### selecting categorical values with `==`\n",
    "\n",
    "`df.query('column==\"value\" or (column == \"value\" and other_value < 90)')`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13c1f15",
   "metadata": {},
   "source": [
    "## .melt() method\n",
    "\n",
    "`df.melt(id_vars=['id1', 'id2'])`\n",
    "> <span style = \"color:royalblue\"> `id_vars` create columns to be used as identifier variables. We can also think of them as columns in our original dataset that we do not want to change. </span>\n",
    "\n",
    "\n",
    "#### wide data (easily read by human intelligence)\n",
    "\n",
    "- each row deals with an independent subject\n",
    "\n",
    "#### long data (easily read by artificial intelligence)\n",
    "\n",
    "- information about one subject is found over many rows, and each one has some attribute about the subject\n",
    "\n",
    "### How to control which columns are unpivoted\n",
    "\n",
    "`df.melt(id_vars=['id1', 'id2'], value_vars['id3', 'id4')`\n",
    "> <span style = \"color:royalblue\"> `value_vars` can be thought of identifying which values will be unpivoted (or added to the new df)</span>\n",
    "\n",
    "\n",
    "### How to change the 'variable' and 'value' columns in new df\n",
    "\n",
    "`df.melt(id_vars=['id1', 'id2'], value_vars['id3', 'id4'),\n",
    "         var_name= ['new_id'], value_name='new_id2'`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
